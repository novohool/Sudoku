def load_sudoku_data(config):
    """加载数独数据集并分割为训练和评估集"""
    try:
        df = pd.read_csv(config.dataset_path)
        logging.info(f'Loaded {len(df)} Sudoku puzzles from {config.dataset_path}')
    except FileNotFoundError:
        logging.error(f'File {config.dataset_path} not found!')
        return [], []
    except Exception as e:
        logging.error(f'Error loading Sudoku data: {e}')
        return [], []

    train_data = []
    eval_data = []
    total_size = len(df)
    eval_size = int(total_size * 0.2)
    train_size = total_size - eval_size

    # 逐行处理数据，避免一次性加载所有数据到内存
    for idx, row in df.iterrows():
        puzzle_str = row['puzzle']
        solution_str = row['solution']
        formatted_puzzle = format_grid(puzzle_str)
        prompt = f'Solve this 9x9 Sudoku puzzle:\n{formatted_puzzle}\nProvide step-by-step reasoning in <think> tags and the final grid in <answer> tags.'
        clues = sum(1 for c in puzzle_str if c != '0')
        difficulty = 1 if clues >= 50 else 2 if clues >= 40 else 3 if clues >= 30 else 4
        data = {
            'prompt': prompt,
            'puzzle': puzzle_str,
            'solution': solution_str,
            'formatted_puzzle': formatted_puzzle,
            'formatted_solution': format_grid(solution_str),
            'difficulty': difficulty,
        }
        if idx < train_size:
            train_data.append(data)
        else:
            eval_data.append(data)

    logging.info(f'Split into {len(train_data)} training examples and {len(eval_data)} evaluation examples')
    return train_data, eval_data

train_data, eval_data = load_sudoku_data(config)
train_dataset = Dataset.from_list(train_data)
eval_dataset = Dataset.from_list(eval_data)
